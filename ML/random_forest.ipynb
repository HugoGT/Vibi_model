{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import mean_squared_error \n",
    "from sklearn.metrics import r2_score \n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:/Users/Clarita/Desktop/HENRY/vibi/Vibi_model/ETL/dataset/data_casa_depto.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'price', 'area', 'bath', 'room', 'parking', 'year',\n",
       "       'property_type', 'near_cc', 'near_school', 'near_parks', 'near_avenue',\n",
       "       'security', 'elevator', 'rest_area', 'pool', 'ranking'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['price'])\n",
    "Y = df[\"price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_model = RandomForestRegressor()\n",
    "\n",
    "linear_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raíz del error cuadrático medio en Test x: 27156\n"
     ]
    }
   ],
   "source": [
    "y_pred = linear_model.predict(X_test)\n",
    "rmse_test= (mean_squared_error(y_test, y_pred, squared = False))\n",
    "print(f'Raíz del error cuadrático medio en Test x: {round(rmse_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(R^2): 0.7601130453069594\n"
     ]
    }
   ],
   "source": [
    "r2 = r2_score(y_test, y_pred) \n",
    "print('(R^2):', r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],           # Número de árboles en el ensamble\n",
    "    'max_depth': [None, 10, 20, 30],          # Profundidad máxima de los árboles\n",
    "    'min_samples_split': [2, 5, 10],         # Mínimo de muestras para dividir un nodo\n",
    "    'min_samples_leaf': [1, 2, 4],           # Mínimo de muestras en las hojas\n",
    "    'max_features': ['sqrt', 'log2'] # Número de características a considerar en cada división\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores hiperparámetros: {'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 300}\n",
      "Mejor Score: 0.7493312601832667\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Instancio\n",
    "random = RandomForestRegressor()\n",
    "\n",
    "# Le pasamos la grilla que creamos\n",
    "model = GridSearchCV(random, param_grid=param_grid, cv=5)\n",
    "\n",
    "# Entrenamos\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Mejores hiperparámetros: \"+str(model.best_params_))\n",
    "print(\"Mejor Score: \"+str(model.best_score_)+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 1324593765.1514826\n",
      "Mean Absolute Error (MAE): 26418.090131259116\n",
      "R-squared (R^2): 0.5670450984431532\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Supongamos que tienes tus datos de entrenamiento y prueba en X_train, y_train, X_test, y_test\n",
    "\n",
    "# Divide tus datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Crea el modelo KNN Regressor\n",
    "knn_regressor = KNeighborsRegressor(n_neighbors=5)  # Puedes ajustar el valor de \"n_neighbors\"\n",
    "\n",
    "# Entrena el modelo\n",
    "knn_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Realiza predicciones en el conjunto de prueba\n",
    "y_pred = knn_regressor.predict(X_test)\n",
    "\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"R-squared (R^2): {r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 9],            # Número de vecinos\n",
    "    'weights': ['uniform', 'distance'],     # Peso de los vecinos (uniforme o por distancia)\n",
    "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],  # Algoritmo de búsqueda de vecinos\n",
    "    'leaf_size': [10, 20, 30],             # Tamaño de hoja para los algoritmos tree-based\n",
    "    'p': [1, 2],                           # Parámetro para la métrica de distancia (1 para Manhattan, 2 para Euclidiana)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores hiperparámetros: {'algorithm': 'brute', 'leaf_size': 10, 'n_neighbors': 9, 'p': 1, 'weights': 'distance'}\n",
      "Mejor Score: 0.626668542174819\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Instancio\n",
    "knn = KNeighborsRegressor()\n",
    "\n",
    "# Le pasamos la grilla que creamos\n",
    "model = GridSearchCV(knn, param_grid=param_grid, cv=5)\n",
    "\n",
    "# Entrenamos\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Mejores hiperparámetros: \"+str(model.best_params_))\n",
    "print(\"Mejor Score: \"+str(model.best_score_)+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared (R^2): 0.7519951978861257\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "gb_regressor = GradientBoostingRegressor( loss= 'huber',n_estimators=300, learning_rate=0.1, max_depth=5, random_state=42,  min_samples_leaf= 4, min_samples_split= 5)\n",
    "\n",
    "# Entrena el modelo\n",
    "gb_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Realiza predicciones en el conjunto de prueba\n",
    "y_pred = gb_regressor.predict(X_test)\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"R-squared (R^2): {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],           # Número de estimadores (árboles) en el ensamble       \n",
    "    'max_depth': [3, 4, 5, 6],               # Profundidad máxima de los árboles base\n",
    "    'min_samples_split': [2, 5, 10],         # Mínimo de muestras para dividir un nodo interno\n",
    "    'min_samples_leaf': [1, 2, 4],           # Mínimo de muestras en una hoja\n",
    "    'loss': ['ls', 'lad', 'huber']         # Función de pérdida (least squares, least absolute deviation, huber)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Clarita\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "1080 fits failed out of a total of 1620.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "540 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Clarita\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Clarita\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 420, in fit\n",
      "    self._validate_params()\n",
      "  File \"c:\\Users\\Clarita\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Clarita\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingRegressor must be a str among {'huber', 'squared_error', 'absolute_error', 'quantile'}. Got 'ls' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "540 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Clarita\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Clarita\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 420, in fit\n",
      "    self._validate_params()\n",
      "  File \"c:\\Users\\Clarita\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Clarita\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of GradientBoostingRegressor must be a str among {'huber', 'squared_error', 'absolute_error', 'quantile'}. Got 'lad' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\Clarita\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.7193553  0.73203319 0.73560233 0.7205075  0.73009563 0.73511503\n",
      " 0.71974217 0.72911305 0.7334612  0.72009572 0.73171614 0.73522385\n",
      " 0.7202736  0.73150465 0.73499251 0.72003262 0.73145877 0.73481708\n",
      " 0.72037776 0.73078717 0.73409766 0.72040106 0.73087565 0.73408605\n",
      " 0.72027224 0.73138091 0.73367733 0.73164192 0.74010192 0.7428598\n",
      " 0.73299633 0.74232189 0.74501758 0.73344246 0.74092673 0.74469757\n",
      " 0.73255484 0.74140048 0.7429153  0.73269996 0.74006757 0.74290779\n",
      " 0.73268596 0.73918922 0.74082028 0.73380093 0.74103968 0.74401453\n",
      " 0.73385679 0.74106601 0.74380973 0.73427106 0.74121608 0.74391978\n",
      " 0.7418345  0.74843006 0.74742557 0.74063758 0.74737343 0.74781832\n",
      " 0.74057773 0.7462744  0.74801748 0.74272272 0.74791221 0.75021844\n",
      " 0.74317503 0.7465674  0.75012675 0.74127573 0.74652887 0.74708128\n",
      " 0.74350868 0.74885821 0.75113342 0.74341515 0.74919633 0.75146471\n",
      " 0.74344841 0.7489935  0.7513296  0.74349407 0.74687337 0.74678691\n",
      " 0.74543842 0.75050438 0.7481459  0.74575083 0.74677256 0.74758192\n",
      " 0.74602549 0.75082834 0.75013305 0.74656156 0.74982444 0.74818732\n",
      " 0.74699285 0.75090212 0.75107811 0.74564847 0.74913952 0.74843985\n",
      " 0.74706383 0.75040337 0.74851939 0.74637944 0.75057869 0.75003739]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores hiperparámetros: {'loss': 'huber', 'max_depth': 5, 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 300}\n",
      "Mejor Score: 0.7514647105511532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Instancio\n",
    "gb = GradientBoostingRegressor()\n",
    "\n",
    "# Le pasamos la grilla que creamos\n",
    "model = GridSearchCV(gb, param_grid=param_grid, cv=5)\n",
    "\n",
    "# Entrenamos\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Mejores hiperparámetros: \"+str(model.best_params_))\n",
    "print(\"Mejor Score: \"+str(model.best_score_)+'\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
